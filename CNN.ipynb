{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YjfYrf6iJOy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# ====================== 参数设置 ======================\n",
        "batch_size = 64                  # 每个批次的样本数量 <<< 可调参数\n",
        "num_epochs = 10                  # 训练轮数 <<< 可调参数\n",
        "learning_rate = 0.001            # 学习率 <<< 可调参数\n",
        "num_classes = 10                 # 类别数，例如10类手写数字 <<< 可调参数\n",
        "image_size = 28                  # 图像尺寸（高度/宽度） <<< 可调参数\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # 使用GPU或CPU\n",
        "\n",
        "# ====================== 数据加载与预处理 ======================\n",
        "# 定义图像的预处理流程\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(),                      # 转为灰度图像（如为彩色图像可去掉） <<< 可调\n",
        "    transforms.Resize((image_size, image_size)), # 调整为统一尺寸 <<< 可调参数\n",
        "    transforms.ToTensor(),                       # 转换为Tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))         # 归一化处理 <<< 可调参数（根据图像通道均值/方差）\n",
        "])\n",
        "\n",
        "# 加载训练图像数据集，目录结构应为：train/class_name/image.png\n",
        "train_dataset = ImageFolder(root='train', transform=transform)  # <<< 可调参数（路径）\n",
        "\n",
        "# 将训练集按 8:2 分为训练集和验证集\n",
        "train_size = int(0.8 * len(train_dataset))  # 训练集占80%\n",
        "val_size = len(train_dataset) - train_size  # 剩下为验证集\n",
        "train_set, val_set = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# 创建数据加载器（DataLoader）\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)  # 打乱训练集\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size)                    # 验证集无需打乱\n",
        "\n",
        "# ====================== 定义 CNN 模型 ======================\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # 第一层卷积（灰度图输入通道为1） <<< 可调\n",
        "            nn.ReLU(),                                   # 激活函数\n",
        "            nn.MaxPool2d(2),                             # 最大池化，尺寸减半（28 -> 14）\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # 第二层卷积 <<< 可调\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),                             # 尺寸减半（14 -> 7）\n",
        "        )\n",
        "        self.dropout = nn.Dropout(0.25)                  # Dropout防止过拟合 <<< 可调参数\n",
        "        self.fc = nn.Linear(64 * 7 * 7, num_classes)     # 全连接层 <<< 可调（根据输出大小与类别数）\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)                                 # 卷积层\n",
        "        x = x.view(-1, 64 * 7 * 7)                        # 拉平为一维向量\n",
        "        x = self.dropout(x)                              # Dropout层\n",
        "        x = self.fc(x)                                   # 全连接输出\n",
        "        return x\n",
        "\n",
        "model = CNN().to(device)  # 模型放到GPU或CPU上\n",
        "\n",
        "# ====================== 损失函数与优化器 ======================\n",
        "criterion = nn.CrossEntropyLoss()                        # 多分类交叉熵损失\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Adam优化器 <<< 可调\n",
        "\n",
        "# ====================== 评估函数 ======================\n",
        "def evaluate(loader):\n",
        "    model.eval()                                         # 进入评估模式\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    with torch.no_grad():                               # 不计算梯度\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * labels.size(0)   # 累加总损失\n",
        "            preds = outputs.argmax(1)                    # 取预测结果\n",
        "            correct += (preds == labels).sum().item()    # 正确预测数\n",
        "            total += labels.size(0)                      # 总样本数\n",
        "    return total_loss / total, correct / total           # 返回平均损失和准确率\n",
        "\n",
        "# ====================== 训练循环 ======================\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()                                        # 训练模式\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()                            # 梯度清零\n",
        "        outputs = model(images)                          # 前向传播\n",
        "        loss = criterion(outputs, labels)                # 计算损失\n",
        "        loss.backward()                                  # 反向传播\n",
        "        optimizer.step()                                 # 更新参数\n",
        "\n",
        "        total_loss += loss.item() * labels.size(0)\n",
        "        preds = outputs.argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_loss = total_loss / total\n",
        "    train_acc = correct / total\n",
        "    val_loss, val_acc = evaluate(val_loader)             # 在验证集上评估\n",
        "    print(f'Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}')\n",
        "\n",
        "# ====================== 测试集预测并生成 submission.csv ======================\n",
        "# 测试数据加载（ImageFolder测试集标签默认为 0） <<< 可调\n",
        "test_dataset = ImageFolder(root='test', transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, _ in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = outputs.argmax(1)\n",
        "        all_preds.append(preds.cpu())\n",
        "\n",
        "# 拼接所有预测结果\n",
        "final_predictions = torch.cat(all_preds).numpy()\n",
        "\n",
        "# 创建 submission.csv\n",
        "submission = pd.DataFrame({\n",
        "    'id': list(range(len(final_predictions))),  # 假设文件顺序和预测顺序一致 <<< 可调\n",
        "    'label': final_predictions\n",
        "})\n",
        "submission.to_csv('submission.csv', index=False)         # 保存预测结果\n",
        "print(\"预测结果已保存为 submission.csv\")\n"
      ]
    }
  ]
}